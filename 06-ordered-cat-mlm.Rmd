# Ordered Categories and Multilevel Models {#week-6}

The sixth week covers [Chapter 12 (Monsters and Mixtures)](https://bookdown.org/content/4857/monsters-and-mixtures.html) and [Chapter 13 (Models With Memory)](https://bookdown.org/content/4857/models-with-memory.html). Chapter 13 is also covered in [Week 7](#week-7), so those exercises are included in that week.

## Lectures

Lecture 11:

```{r lecture-11, echo = FALSE, out.width = "100%"}
knitr::include_url("https://www.youtube.com/embed/-397DMPooR8")
```

Lecture 12:

```{r lecture-12, echo = FALSE, out.width = "100%"}
knitr::include_url("https://www.youtube.com/embed/SocRgsf202M")
```

## Exercises

### Chapter 12

:::question
> **12E1.** What is the difference between an *ordered* categorical variable and an unordered one? Define and then give an example of each.
:::

Both ordered and unordered variables are constrained to discrete values. However, ordered variables have a fixed order to the magnitudes, although not necessarily a fixed distance between values. For example, education level (high school, undergraduate, postgraduate), population density (rural, suburban, urban), and socioeconomic status (low, high) could all be conceived of as. Unordered variables have no ordering. For example, gender (male, female, non-binary) and race (African American, Asian, White, etc.) have no ordering. That is, no categories is "more" or "greater" than another.


:::question
> **12E2.** What kind of link function does an ordered logistic regression employ? How does it differ from an ordinary logit link?
:::

And ordered logistic regression uses the cumulative logit link function. Whereas the normal logit link can be used the represent a discrete probability of a single event, the cumulative logit link represents the cumulative probability of an event. That is, the linear model with the cumulative logit link function defines the log-odds of the the specified category *or lower*.


:::question
> **12E3.** When count data are zero-inflated, using a model that ignores zero-inflation will tend to induce which kind of inferential error?
:::

Ignoring zero-inflation will result in an underestimate of the event rate. If there are additional zeros, the mean will necessarily be lower. So if we treat the data as a single process, rather than multiple processes, we will estimate a lower mean rate.


:::question
> **12E4.** Over-dispersion is common in count data. Give an example of a natural process that might produce over-dispersed counts. Can you also give an example of a process that might produce *under*-dispersed counts?
:::

Over-dispersion occurs whenever there is variation in the rates. This could be common, for example, in restaurants. So you work at a large restaurant chain and are estimating the number of desserts sold across all of the franchises over the last month. The aggregated counts will likely be over-dispersed because some franchises sell more desserts than others (i.e., the average rate is not the same across franchises).

Under-dispersion is the opposite effect. This is when there is less variation than might be expected. This can occur when there is high auto-correlation between observed counts. Continuing with the restaurant theme, imagine we are estimating how many orders are filled an hour. It's plausible that the rate at which orders are filled would be partially dependent on how many orders are waiting to be filled (i.e., we might work faster if there are a lot of people waiting). In this type of queued-data model, the counts will be highly correlated, and my be under-dispersed.


:::question
> **12M1.** At a certain university, employees are annually rated from 1 to 4 on their productivity, with 1 being least productive and 4 most productive. In a certain department at this university in a certain year, the numbers of employees receiving each rating were (from 1 to 4): 12, 36, 7, 41. Compute the log cumulative odds of each rating.
:::

```{r e12m1-1}
# raw counts
counts <- c(12, 36, 7, 41)
counts

# raw proportions
props <- counts / sum(counts)
props

# cumulative proportions
cum_props <- cumsum(props)
cum_props

# cumulative log odds
log(cum_props / (1 - cum_props))
```


:::question
> **12M2.** Make a version of Figure 12.5 for the employee ratings data given just above.
:::

```{r e12m2-1}
tibble(rating = c(1:4),
       cum_props = cum_props,
       start = lag(cum_props, default = 0)) %>% 
  ggplot(aes(x = rating, y = cum_props)) +
  geom_point(size = 3) +
  geom_line() +
  geom_segment(aes(x = rating, xend = rating, y = 0, yend = cum_props), size = 2) +
  geom_segment(aes(x = rating + 0.05, xend = rating + 0.05,
                   y = start, yend = cum_props),
               color = "#009FB7", size = 2) +
  geom_text(aes(x = rating + 0.1, y = (start + cum_props) / 2, label = rating),
            color = "#009FB7", size = 4) +
  labs(x = "Rating", y = "Cumulative proportion")
```


:::question
> **12M3.** Can you modify the derivation of the zero-inflated Poisson distribution (ZIPoisson) from the chapter to construct a zero-inflated binomial distribution?
:::

Like the ZIPoisson, the ZIBinomial has two ways that we can observe a 0. There is a single probability that determines whether or not a 0 is observed in the first process, $p_0$. When a 0 is not observed from the first process, we still might observe a 0 from the binomial process. For the binomial, we'll define the probability of success as $q$, and have $n$ trials. Combining the two processes, the probability of any 0 is:

$$
\Pr(0|p_0,q,n)=p_0 + (1 - p_0)(1 - q)^n
$$

In word form, we get a 0 from process one with probability $p_0$. Then, if not from process one (i.e., $(1-p_0)$), we could observe a 0 from the binomial model. That is, the probability of not success is $(1-q)$, raised to the number of trials, $n$.

Similarly, the probability of any non-zero observation is:

$$
\Pr(y|p_0,q,n) = (1-p_0)\frac{n!}{y!(n-y)!}q^y(1-q)^{n-y}
$$

This expression is the the binomial model, with $(1-p_0)$ appended to the front. That is, this is the binomial probability of observing a given value, times the probability that the first process didn't generate a 0.


:::{.question .code-question}
> **12H1.** In 2014, a paper was published that was entitled "Female hurricanes are deadlier than male hurricanes." As the title suggests, the paper claimed that hurricanes with female names have caused greater loss of life, and the explanation given is that people unconsciously rate female hurricanes as less dangerous and so are less likely to evacuate. Statisticians severely criticized the paper after publication. Here, you'll explore the complete data used in the paper and consider the hypothesis that hurricanes with female names are deadlier. Load the data with:

```{r e12h1-inst, message = FALSE}
library(rethinking)
data(Hurricanes)
```

> Acquaint yourself with the columns by inspecting the help `?Hurricanes`. In this problem, you'll focus on predicting `deaths` using `femininity` as a predictor. You can use `quap` or `ulam`. Compare the model to an intercept-only Poisson model of `deaths`. How strong is the association between femininity of name and deaths? Which storms does the model fit (retrodict) well? Which storms does it fit poorly?
:::

Let's start by loading the data and doing from prior predictive simulations. For our priors, we'll use a $\text{Normal}(1, 1)$ for the intercept, and a $\text{Normal}(0, 1)$ for the slope of femininity. This results in a relatively low number of deaths on average, which is consistent with what we know about most hurricanes. There are a few lines with slopes so large as to not be very plausible. We could tighten the slope prior, but for now this is probably sufficient.

```{r e12h1-1}
hurr_dat <- Hurricanes %>% 
  as_tibble() %>% 
  mutate(femininity_std = standardize(femininity),
         min_pressure_std = standardize(min_pressure),
         damage_norm_std = standardize(damage_norm),
         damage_norm_log_std = standardize(log(damage_norm)),
         fem_discrete = case_when(femininity_std < 0 ~ "Masculine",
                                  TRUE ~ "Feminine"))

b12h1_p <- brm(deaths ~ 1 + femininity_std, data = hurr_dat, family = poisson,
               prior = c(prior(normal(1, 1), class = Intercept),
                         prior(normal(0, 1), class = b)),
               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
               sample_prior = "only", file = here("fits", "chp12", "b12h1-p"))

tibble(femininity_std = seq(-2, 2, length.out = 100)) %>% 
  add_epred_draws(b12h1_p, ndraws = 50) %>% 
  ggplot(aes(x = femininity_std, y = .epred, group = .draw)) +
  geom_line(alpha = 0.4) +
  coord_cartesian(ylim = c(0, 500)) +
  labs(x = "Name femininity (standardized)", y = "Deaths")
```

Now let's fit our intercept-only model and the model that include femininity. In the summary for `b12h1`, we see that there is fairly moderate positive relationship between name femininity and deaths. When we compare the models, we see that the model including femininity is preferred; however, the standard error of the difference between the model is about 3 times large than the difference so PSIS isn't really able to differentiate the models very well. Additionally, we get some warninging about some very large Pareto values.

```{r e12h1-2, message = FALSE}
b12h1_i <- brm(deaths ~ 1, data = hurr_dat, family = poisson,
               prior = c(prior(normal(1, 1), class = Intercept)),
               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
               file = here("fits", "chp12", "b12h1-i"))

b12h1 <- brm(deaths ~ 1 + femininity_std, data = hurr_dat, family = poisson,
             prior = c(prior(normal(1, 1), class = Intercept),
                       prior(normal(0, 1), class = b)),
             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
             file = here("fits", "chp12", "b12h1"))

b12h1_i <- add_criterion(b12h1_i, criterion = "loo")
b12h1 <- add_criterion(b12h1, criterion = "loo")

loo_compare(b12h1_i, b12h1)

summary(b12h1)
```

Let's look at the model predictions to see what is going on. You can't see it, but there is a very narrow compatibility interval around the fitted line. The grey sampling distribution is at least visible, but that is also quite narrow. Overall, it appears that there are a few very extreme storms with high femininity names that are driving the trend, and also likely leading to our high Pareto warnings. We can see that there is a lot of over-dispersion, so we'll need a more flexible model to really understand what is happening in this data.

```{r e12h1-3}
full_join(
  tibble(femininity_std = seq(-2, 1.5, length.out = 100)) %>% 
    add_epred_draws(b12h1),
  tibble(femininity_std = seq(-2, 1.5, length.out = 100)) %>% 
    add_predicted_draws(b12h1),
  by = c("femininity_std", ".row", ".chain", ".iteration", ".draw")
) %>% 
  ggplot(aes(x = femininity_std)) +
  stat_lineribbon(aes(y = .prediction), .width = 0.89, size = 0,
                  fill = "grey80") +
  stat_lineribbon(aes(y = .epred), .width = c(0.67, 0.89, 0.97), size = 0.5) +
  geom_point(data = hurr_dat, aes(x = femininity_std, y = deaths)) +
  scale_fill_manual(values = ramp_blue(seq(1, 0.2, length.out = 3)),
                    breaks = c(0.67, 0.89, 0.97)) +
  scale_x_continuous(breaks = seq(-2, 1.5, by = 0.5)) +
  labs(x = "Name Femininity (standardized)", y = "Deaths", fill = "Interval")
```


:::question
> **12H2.** Counts are nearly always over-dispersed relative to Poisson. So fit a gamma-Poisson (aka negative-binomial) model to predict `deaths` using `femininity`. Show that the over-dispersed model no longer shows as precise a positive association between femininity and deaths, with an 89% interval that overlaps zero. Can you explain why the association diminished in strength?
:::

Here's out we fit the gamma-Poisson model in {brms}. It looks exactly the same as model `b12h1`, except now instead of `family = poisson` we use `family = negbinomial`.

```{r e12h2-1}
b12h2 <- brm(deaths ~ 1 + femininity_std, data = hurr_dat, family = negbinomial,
             prior = c(prior(normal(1, 1), class = Intercept),
                       prior(normal(0, 1), class = b)),
             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
             file = here("fits", "chp12", "b12h2"))

summary(b12h2, prob = 0.89)
```

As indicated in the question, the 89% interval for `femininity_std` does indeed overlap 0. Let's directly compare the parameter estimates from the two models. We can see that the point estimates for the Intercept and slope for femininity are almost the same in both models, but there is much more uncertainty in the negative binomial.

```{r e12h2-2}
b12h1_params <- as_draws_df(b12h1) %>% 
  as_tibble() %>% 
  select(b_Intercept, b_femininity_std) %>% 
  pivot_longer(everything(), names_to = "parameter", values_to = "value") %>% 
  group_by(parameter) %>% 
  mean_qi(.width = 0.89) %>% 
  mutate(model = "Poisson")

b12h2_params <- as_draws_df(b12h2) %>% 
  as_tibble() %>% 
  select(b_Intercept, b_femininity_std, shape) %>% 
  pivot_longer(everything(), names_to = "parameter", values_to = "value") %>% 
  group_by(parameter) %>% 
  mean_qi(.width = 0.89) %>% 
  mutate(model = "Negative Binomial")

bind_rows(b12h1_params, b12h2_params) %>% 
  mutate(parameter = factor(parameter,
                            levels = c("b_Intercept", "b_femininity_std",
                                       "shape"),
                            labels = c("Intercept",
                                       "&beta;<sub>Femininity</sub>",
                                       "Shape")),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = value, y = fct_rev(model))) +
  facet_wrap(~parameter, nrow = 1) +
  geom_pointinterval(aes(xmin = .lower, xmax = .upper)) +
  labs(x = "Parameter value", y = NULL)
```

Why more uncertainty? Because each hurricane can now have its own expected death rate. That is, given a femininity score, there is a distribution of gamma distributions that the death rate can be sampled from. For example, here are the distributions of gamma distributions for 3 values of femininity. Because any combination of intercept and slope values can now produce many different death rates, more values of the intercept and slope are plausible. This is what results in the wider posterior intervals in the negative binomial model.

```{r e12h2-3}
dists <- as_draws_df(b12h2) %>% 
  as_tibble() %>% 
  select(.chain, .iteration, .draw, b_Intercept, b_femininity_std, shape) %>% 
  filter(.draw %in% sample(1:n(), size = 100)) %>% 
  mutate(fem = -1) %>% 
  complete(nesting(.chain, .iteration, .draw, b_Intercept, b_femininity_std,
                   shape), fem = c(-1, 0, 1)) %>% 
  select(b_Intercept, b_femininity_std, shape, fem) %>% 
  pmap_dfr(function(b_Intercept, b_femininity_std, shape, fem) {
    tibble(x = 0:70) %>% 
      mutate(y = dgamma2(x, mu = exp(b_Intercept + b_femininity_std * fem),
                         scale = shape),
             fem_score = glue("Femininity = {fem}"))
  }, .id = ".draw")

ggplot(dists, aes(x = x, y = y, group = .draw)) +
  facet_wrap(~fem_score, nrow = 1) +
  geom_line(alpha = 0.2) +
  labs(x = "Deaths", y = "Density")
```

Finally, let's look at the prediction for this model. A little better, but still pretty bad overall.

```{r e12h2-4}
full_join(
  tibble(femininity_std = seq(-2, 1.5, length.out = 100)) %>% 
    add_epred_draws(b12h2),
  tibble(femininity_std = seq(-2, 1.5, length.out = 100)) %>% 
    add_predicted_draws(b12h2),
  by = c("femininity_std", ".row", ".chain", ".iteration", ".draw")
) %>% 
  ggplot(aes(x = femininity_std)) +
  stat_lineribbon(aes(y = .prediction), .width = 0.89, size = 0,
                  fill = "grey80") +
  stat_lineribbon(aes(y = .epred), .width = c(0.67, 0.89, 0.97), size = 0.5) +
  geom_point(data = hurr_dat, aes(x = femininity_std, y = deaths)) +
  scale_fill_manual(values = ramp_blue(seq(1, 0.2, length.out = 3)),
                    breaks = c(0.67, 0.89, 0.97)) +
  scale_x_continuous(breaks = seq(-2, 1.5, by = 0.5)) +
  labs(x = "Name Femininity (standardized)", y = "Deaths", fill = "Interval")
```


:::question
> **12H3.** In the data, there are two measures of a hurricane’s potential to cause death: `damage_norm` and `min_pressure.` Consult `?Hurricanes` for their meanings. It makes some sense to imagine that femininity of a name matters more when the hurricane is itself deadly. This implies an interaction between `femininity` and either or both of `damage_norm` and `min_pressure`. Fit a series of models evaluating these interactions. Interpret and compare the models. In interpreting the estimates, it may help to generate counterfactual predictions contrasting hurricanes with masculine and feminine names. Are the effect sizes plausible?
:::

For this question, we'll fit two interaction models: one with `min_pressure` and one with `damage_norm`. We'll start with `min_pressure`, and we'll continue to use the negative binomial model, given the findings of the last question. In the model summary, we see that `min_pressure` has a negative coefficient. This makes sense, given that hurricanes actually get stronger as the minimum pressure drops. So we might expect higher pressure (i.e., an increase in `min_pressure`) to lead to weaker storms, and therefore fewer deaths.

```{r e12h3-1}
b12h3_mp <- brm(deaths ~ 1 + femininity_std * min_pressure_std,
                data = hurr_dat, family = negbinomial,
                prior = c(prior(normal(1, 1), class = Intercept),
                          prior(normal(0, 1), class = b)),
                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
                file = here("fits", "chp12", "b12h3-mp"))

summary(b12h3_mp)
```

The interaction for generalized models is tricky to interpret on its own, so we'll plot out the predictions to get a sense of what the model is doing. We see that this plot is showing the opposite of the trend implied by the paper. That is, for the most dangerous storm (i.e., those with the lowest pressure), it appears that having a masculine name leads to more deaths than a feminine name. However, we should note that the 89% intervals for both of the trends are overlapping a significant amount, so there isn't much evidence of a meaningful interaction here.

```{r e12h3-2, cache = TRUE}
crossing(min_pressure_std = seq(-3, 2, length.out = 100),
         femininity_std = c(-1, 1)) %>% 
  add_epred_draws(b12h3_mp) %>% 
  mean_qi(.width = 0.89) %>% 
  mutate(femininity_std = factor(femininity_std,
                                 labels = c("Masculine", "Feminine")),
         across(c(.epred, .lower, .upper), ~sqrt(.x))) %>% 
  ggplot(aes(x = min_pressure_std)) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper, fill = femininity_std),
              alpha = 0.4, show.legend = FALSE) +
  geom_line(aes(y = .epred, color = femininity_std), size = 1) +
  geom_point(data = hurr_dat,
             aes(y = sqrt(deaths), color = fem_discrete)) +
  scale_fill_okabeito() +
  scale_color_okabeito(labels = c("Masculine", "Feminine")) +
  labs(x = "Minimum pressure (standardized)", y = "Deaths (sqrt)",
       color = NULL)
```

Now for the other interaction, that of `damage_norm`.

```{r e12h3-3}
b12h3_dn <- brm(deaths ~ 1 + femininity_std * damage_norm_log_std,
                data = hurr_dat, family = negbinomial,
                prior = c(prior(normal(1, 1), class = Intercept),
                          prior(normal(0, 1), class = b)),
                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
                file = here("fits", "chp12", "b12h3-dn"))

summary(b12h3_dn)
```

Once we have added property damage to the model, we see that there is almost no effect of name femininity. Let's again look at some counterfactual predictions. This actually shows the relationship implied by the paper. That is, as damage increases, feminine-named storms have more deaths. However, again, there is very little difference between the feminine and masculine names.

```{r e12h3-4, cache = TRUE}
crossing(damage_norm_log_std = seq(-3.5, 2, length.out = 100),
         femininity_std = c(-1, 1)) %>% 
  add_epred_draws(b12h3_dn) %>% 
  mean_qi(.width = 0.89) %>% 
  mutate(femininity_std = factor(femininity_std,
                                 labels = c("Masculine", "Feminine")),
         across(c(.epred, .lower, .upper), ~sqrt(.x))) %>% 
  ggplot(aes(x = damage_norm_log_std)) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper, fill = femininity_std),
              alpha = 0.4, show.legend = FALSE) +
  geom_line(aes(y = .epred, color = femininity_std), size = 1) +
  geom_point(data = hurr_dat,
             aes(y = sqrt(deaths), color = fem_discrete)) +
  scale_fill_okabeito() +
  scale_color_okabeito(labels = c("Masculine", "Feminine")) +
  labs(x = "Property Damage (log, standardized)", y = "Deaths (sqrt)",
       color = NULL)
```

Overall, from this question and the previous, there doesn't appear to be a strong relationship between name femininity and deaths, or any significant interactions. Rather, the trends are driven by a few extreme storms which just happened to have feminine names. Sometimes things really are just random, especially in small samples!


:::question
> **12H4.** In the original hurricanes paper, storm damage (`damage_norm`) was used directly. This assumption implies that mortality increases exponentially with a linear increase in storm strength, because a Poisson regression uses a log link. So it’s worth exploring an alternative hypothesis: that the logarithm of storm strength is what matters. Explore this by using the logarithm of `damage_norm` as a predictor. Using the best model structure from the previous problem, compare a model that uses `log(damage_norm)` to a model that uses `damage_norm` directly. Compare their PSIS/WAIC values as well as their implied predictions. What do you conclude?
:::

The previous problem used the log-standardized `damage_norm`, we we'll fit the non-log version here.

```{r e12h4-1}
b12h4_dn <- brm(deaths ~ 1 + femininity_std * damage_norm_std,
                data = hurr_dat, family = negbinomial,
                prior = c(prior(normal(1, 1), class = Intercept),
                          prior(normal(0, 1), class = b)),
                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
                file = here("fits", "chp12", "b12h4-dn"))

b12h3_dn <- add_criterion(b12h3_dn, criterion = "loo")
b12h4_dn <- add_criterion(b12h4_dn, criterion = "loo")

loo_compare(b12h3_dn, b12h4_dn)
```

Comparing the two models, we see that PSIS pretty strongly prefers the log-standardized version. Why? Let's plot the predictions for non-log model. Because we don't take the log, `damage_norm` scale multiplicatively, and predicted deaths increase quickly. The result is that we completely miss the most damaging storms (e.g., Donna, Andrew, and Sandy) in order to fit the less damaging storms, which make up most of the sample.

```{r e12h4-2, cache = TRUE}
crossing(damage_norm_std = seq(-0.75, 5.5, length.out = 30),
         femininity_std = c(-1, 1)) %>% 
  add_epred_draws(b12h4_dn) %>% 
  mean_qi(.width = 0.89) %>% 
  mutate(femininity_std = factor(femininity_std,
                                 labels = c("Masculine", "Feminine")),
         across(c(.epred, .lower, .upper), ~sqrt(.x))) %>% 
  ggplot(aes(x = damage_norm_std)) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper, fill = femininity_std),
              alpha = 0.4, show.legend = FALSE) +
  geom_line(aes(y = .epred, color = femininity_std), size = 1) +
  geom_point(data = hurr_dat,
             aes(y = sqrt(deaths), color = fem_discrete)) +
  geom_text_repel(data = filter(hurr_dat, damage_norm_std > 3),
                  aes(y = sqrt(deaths), label = name)) +
  coord_cartesian(ylim = c(0, 20)) +
  scale_fill_okabeito() +
  scale_color_okabeito(labels = c("Masculine", "Feminine")) +
  labs(x = "Property Damage (standardized)", y = "Deaths (sqrt)",
       color = NULL)
```


:::question
> **12H5.** One hypothesis from developmental psychology, usually attributed to Carol Gilligan, proposes that women and men have different average tendencies in moral reasoning. Like most hypotheses in social psychology, it is descriptive, not causal. The notion is that women are more concerned with care (avoiding harm), while men are more concerned with justice and rights. Evaluate this hypothesis, using the `Trolley` data, supposing that `contact` provides a proxy for physical harm. Are women more or less bothered by contact than are men, in these data? Figure out the model(s) that is needed to address this question.
:::

We have to make extensive use of the non-linear {brms} syntax for this one if we want to use gender as an index variable. There are two parameters that are of primary interest to us in the model summary. First is `a_Intercept`, which is the main effect of being female on the cumulative log-odds, and `bC_maleFemale`, which is the interaction of being both female and in a contact scenario.

The main effect is negative, indicating that overall, females were more likely to give items lower ratings. However, the interaction effect is actually less negative for female than the corresponding parameter for males (`bC_maleMale`). This means that in terms of the contact effect by gender, the data indicates that males were more bothered than females.

```{r e12h5-1}
data(Trolley)

trolley_dat <- Trolley %>% 
  as_tibble() %>% 
  mutate(female = 1L - male,
         female = factor(female, levels = c(0, 1), labels = c("Male", "Female")),
         male = factor(male, levels = c(0, 1), labels = c("Female", "Male")))

b12h5 <- brm(bf(response ~ 1 + a * female + (bA * action) + (bC * contact) +
                  (bI * intention) + (bIA * intention * action) +
                  (bIC * intention * contact),
                a ~ 1,
                bA ~ 0 + male,
                bC ~ 0 + male,
                bI ~ 0 + male,
                bIA ~ 0 + male,
                bIC ~ 0 + male,
                nl = TRUE), data = trolley_dat, family = cumulative,
             prior = c(prior(normal(0, 1.5), class = Intercept),
                       prior(normal(0, 0.5), class = b, nlpar = a),
                       prior(normal(0, 0.5), class = b, nlpar = bA),
                       prior(normal(0, 0.5), class = b, nlpar = bC),
                       prior(normal(0, 0.5), class = b, nlpar = bI),
                       prior(normal(0, 0.5), class = b, nlpar = bIA),
                       prior(normal(0, 0.5), class = b, nlpar = bIC)),
             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
             file = here("fits", "chp12", "b12h5"))

summary(b12h5)
```


:::question
> **12H6.** The data in `data(Fish)` are records of visits to a national park. See `?Fish` for details. The question of interest is how many fish an average visitor takes per hour, when fishing. The problem is that not everyone tried to fish, so the `fish_caught` numbers are zero-inflated. As with the monks example in the chapter, there is a process that determines who is fishing (working) and another process that determines fish per hour (manuscripts per day), conditional on fishing (working). We want to model both. Otherwise we’ll end up with an underestimate of rate of fish extraction from the park.

> You will model these data using zero-inflated Poisson GLMs. Predict `fish_caught` as a function of any of the other variables you think are relevant. One thing you must do, however, is use a proper Poisson offset/exposure in the Poisson portion of the zero-inflated model. Then use the `hours` variable to construct the offset. This will adjust the model for the differing amount of time individuals spent in the park.
:::

```{r e12h6-1}
data(Fish)

fish_dat <- Fish %>% 
  as_tibble() %>% 
  mutate(loghours = log(hours))

b12h6 <- brm(bf(fish_caught ~ 1 + persons + child + offset(loghours),
                zi ~ 1 +persons + child),
             data = fish_dat, family = zero_inflated_poisson,
             prior = c(prior(normal(0, 1), class = Intercept),
                       prior(normal(0, 1), class = Intercept, dpar = zi),
                       prior(normal(0, 0.5), class = b),
                       prior(normal(0, 0.5), class = b, dpar = zi)),
             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
             file = here("fits", "chp12", "b12h6"))

summary(b12h6)
```



:::question
> **12H7.** In the trolley data---`data(Trolley)`---we saw how education level (modeled as an ordered category) is associated with responses. But is this association causal? One plausible confound is that education is also associated with age, through a causal process: People are older when they finish school than when they begin it. Reconsider the Trolley data in this light. Draw a DAG that represents hypothetical causal relationships among response, education, and age. Which statical model or models do you need to evaluate the causal influence of education on responses? Fit these models to the trolley data. What do you conclude about the causal relationships among these three variables?
:::




:::question
> **12H8.** Consider one more variable in the trolley data: Gender. Suppose that gender might influence education as well as response directly. Draw the DAG now that includes response, education, age, and gender. Using only the DAG, is it possible that the inferences from **12H7** above are confounded by gender? If so, define any additional models you need to infer the causal influence of education on response. What do you conclude?
:::




## Homework
